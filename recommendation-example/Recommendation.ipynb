{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\komunyong\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\komunyong\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import copy\n",
    "import util\n",
    "\n",
    "# Transform data\n",
    "parser = lambda date: pd.to_datetime(date)\n",
    "df = dataset = pd.read_excel('dataset.xlsx')\n",
    "\n",
    "# Parse date time\n",
    "df['Date'] = df['Date'].apply(parser)\n",
    "df['transaction_date'] = df['Date'].dt.date\n",
    "df['is_weekend'] = df['Date'].dt.dayofweek.apply(util.is_weekend)\n",
    "df['section_time'] = df['Date'].dt.hour.apply(util.quarter_time)\n",
    "\n",
    "# Parse continous value\n",
    "df['bin_price'] = util.discretize(df['Price'], np.array([1000, 2000, 3000, 4000, 5000, 6000]))\n",
    "df['bin_discount'] = util.discretize(df['Discount'], np.array([100, 200, 300, 500]))\n",
    "df['bin_net'] = util.discretize(df['NMV'], np.array([900, 1800, 2700, 3500, 5000, 6000]))\n",
    "\n",
    "# Parse categories\n",
    "df = df[pd.notnull(df['StuffCategories'])] #  clear null StuffCategories, cause it has only 8 rows\n",
    "data_without_null = copy.copy(df)\n",
    "df['bought_categories'] = df['StuffCategories'].str.split(',')\n",
    "df['bought_categories'] = df['bought_categories'].apply(util.unique_cat)\n",
    "\n",
    "parent_categories = ['lifestyle', 'men_fashion', 'women_fashion']\n",
    "bought_categories = [\n",
    "    'all', 'lifestyle_crafts', 'lifestyle_for_home', 'lifestyle_gadget_tech', \n",
    "    'lifestyle_gift_ideas', 'lifestyle_other', 'lifestyle_phone_accessories', 'lifestyle_sports', \n",
    "    'lifestyle_stationeries', 'men_bags_wallets', 'men_glasses', \n",
    "    'men_hats', 'men_jewelry', 'men_pants', 'men_shoes', 'men_shorts', 'men_tops', \n",
    "    'men_underwear', 'men_watches', 'women_bags_wallets', 'women_dresses', \n",
    "    'women_glasses', 'women_hats', 'women_jackets_blazers', \n",
    "    'women_jewelry', 'women_other', 'women_pants_leggings', 'women_shoes', \n",
    "    'women_shorts', 'women_skirts', 'women_sports', 'women_swimwear', 'women_tops', \n",
    "    'women_watches', 'lifestyle', 'men_fashion', 'women_fashion'\n",
    "]\n",
    "df_cat = pd.DataFrame(index=None, columns=bought_categories)\n",
    "df = pd.concat([df, df_cat]).fillna(0)\n",
    "df = df.apply(util.word_matrix, axis=1)\n",
    "\n",
    "# Drop all unused columns\n",
    "data_without_null = data_without_null.drop('bought_categories', axis=1)\n",
    "df = df.drop('Date', axis=1)\n",
    "df = df.drop('StuffCategories', axis=1)\n",
    "df = df.drop('bought_categories', axis=1)\n",
    "df = df.drop('transaction_date', axis=1)\n",
    "df = df.drop('Price', axis=1)\n",
    "df = df.drop('Discount', axis=1)\n",
    "df = df.drop('NMV', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Predict\n",
    "\n",
    "# cross-validate 10 time, 90/10\n",
    "# to prevent bias in model\n",
    "result_set = []\n",
    "for step in range(0, 10):\n",
    "    \n",
    "    # Split train test each round\n",
    "    expected_test_size = 10\n",
    "    test_percent = ((step + 1) * expected_test_size) / 100\n",
    "    test_data_num = round(len(df) * test_percent)\n",
    "    train_data_num = round(len(df) - test_data_num)\n",
    "    train_data = np.array(df[:test_data_num])\n",
    "    test_data = np.array(df[train_data_num:len(df)])\n",
    "    \n",
    "    # Predict\n",
    "    kmeans = KMeans(n_clusters=len(bought_categories)).fit(train_data)\n",
    "    kmeans.predict(test_data)\n",
    "    \n",
    "    # Map result to labels\n",
    "    result = []\n",
    "    labels = kmeans.labels_\n",
    "    for label in labels:\n",
    "        result = np.append(result, bought_categories[label])\n",
    "    df_result = pd.DataFrame(result)\n",
    "    df_predicted = data_without_null[train_data_num:len(data_without_null)]\n",
    "    dataset_suggested = pd.concat([df_predicted.reset_index(drop=True), df_result], axis=1)\n",
    "    np.append(result_set, dataset_suggested)\n",
    "\n",
    "# Write to output file\n",
    "dataset_suggested.to_csv('output.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
